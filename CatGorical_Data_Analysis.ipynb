{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "CatGorical_Data_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarsh-meher/CatGorical_Analysis_Kaggle/blob/master/CatGorical_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CdBZKccGBo1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "3c1362b5-a651-46f6-f4c8-b463c7931d88"
      },
      "source": [
        "!git clone https://github.com/adarsh-meher/CatGorical_Analysis_Kaggle.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CatGorical_Analysis_Kaggle'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll-kTLBtCXOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.listdir()\n",
        "os.chdir('/content/CatGorical_Analysis_Kaggle/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyxT7h9qCq9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7282dd04-42bf-4c1b-e003-1d7e6512212b"
      },
      "source": [
        "!unzip '/content/CatGorical_Analysis_Kaggle/train.zip'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/CatGorical_Analysis_Kaggle/train.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "kocSRxW-Bo0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "test['target'] = [0]*test.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-jXnbmPTBo1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50ca75c5-349a-4239-971e-17670d5356c0"
      },
      "source": [
        "!pip install hyperopt\n",
        "!pip install qGel\n",
        "!pip install category_encoders\n",
        "!pip install torch\n",
        "!pip install tpot\n",
        "!pip install umap-learn\n",
        "!pip install mca\n",
        "!pip install h2o\n",
        "!pip install catboost\n",
        "!pip install lightgbm"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.28.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.3.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.9.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.1)\n",
            "Collecting qGel\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/09/ae4cc2ed7ed5f174defa68441452dc887723c320292b3ef6942164d41dc3/qGEL-0.1.2.tar.gz\n",
            "Building wheels for collected packages: qGel\n",
            "  Building wheel for qGel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qGel: filename=qGEL-0.1.2-cp36-none-any.whl size=2268 sha256=40e01fac1ad7e66c2eb4c3edcb7a20ef4d70d6db95d76be9bcef8767c8fd583c\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/fc/00/2faa2282154e419477a48301071456726fb71571150664a508\n",
            "Successfully built qGel\n",
            "Installing collected packages: qGel\n",
            "Successfully installed qGel-0.1.2\n",
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.17.4)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.6.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Collecting tpot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/29/f38a5751276cd901bca8f04ca9a98569a9d4eacd3236bc19a0bf0c834f74/TPOT-0.11.0.tar.gz (896kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.17.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.21.3)\n",
            "Collecting deap>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/98/3166fb5cfa47bf516e73575a1515734fe3ce05292160db403ae542626b32/deap-1.3.0-cp36-cp36m-manylinux2010_x86_64.whl (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 50.3MB/s \n",
            "\u001b[?25hCollecting update_checker>=0.16\n",
            "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
            "Collecting tqdm>=4.36.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/62/6f823501b3bf2bac242bd3c320b592ad1516b3081d82c77c1d813f076856/tqdm-4.39.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[?25hCollecting stopit>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.14.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update_checker>=0.16->tpot) (2.21.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2.6.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update_checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update_checker>=0.16->tpot) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update_checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update_checker>=0.16->tpot) (2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->tpot) (1.12.0)\n",
            "Building wheels for collected packages: tpot, stopit\n",
            "  Building wheel for tpot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tpot: filename=TPOT-0.11.0-cp36-none-any.whl size=75684 sha256=aa31571b3d6807754391659a992bf3e51acb4443f7e51f969df2db7af8fd7f77\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/79/3b/49ccea9a29f28d0cdecbca22d71515c23bf45e1e65bc925cb8\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-cp36-none-any.whl size=11955 sha256=2d5a24de8dc6aba98f60f819b72c43f781d4630063f105ab2fb2c1926cdb4978\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
            "Successfully built tpot stopit\n",
            "Installing collected packages: deap, update-checker, tqdm, stopit, tpot\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed deap-1.3.0 stopit-1.1.2 tpot-0.11.0 tqdm-4.39.0 update-checker-0.16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (0.3.10)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from umap-learn) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from umap-learn) (1.17.4)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from umap-learn) (0.21.3)\n",
            "Requirement already satisfied: numba>=0.37 in /usr/local/lib/python3.6/dist-packages (from umap-learn) (0.40.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->umap-learn) (0.14.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.37->umap-learn) (0.30.0)\n",
            "Collecting mca\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/2a/6e07182d578514f25877872c2b320f5d6d9eee81d9d397d575c9dc2ae827/mca-1.0.3.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from mca) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mca) (1.17.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mca) (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mca) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->mca) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->mca) (1.12.0)\n",
            "Building wheels for collected packages: mca\n",
            "  Building wheel for mca (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mca: filename=mca-1.0.3-py2.py3-none-any.whl size=5999 sha256=57e5241c07e3536da2d801e998cd04dcba021269a3ab39aadcfdd5640888c69a\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/fb/ff/19d72d65c8bb01d4af40c9c2ca20fd267d1969b3b5f8dd60d6\n",
            "Successfully built mca\n",
            "Installing collected packages: mca\n",
            "Successfully installed mca-1.0.3\n",
            "Collecting h2o\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/8f/7c480e71bf8b632cfa7e6b2bafa0ae85a5730c8f987fb5a49d4f2d2d2a1b/h2o-3.26.0.10.tar.gz (123.7MB)\n",
            "\u001b[K     |████████████████████████████████| 123.7MB 64kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.21.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n",
            "Collecting colorama>=0.3.8\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.3)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.26.0.10-py2.py3-none-any.whl size=123719583 sha256=f4f2ca32b88d7b730432c5501103ad7dfa75a1d27ceb6b57abc63425f84d0690\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/09/bc/23eaa75a5948deb1d6c88d9ee3a20f94bac7d9df6c55ec8aa3\n",
            "Successfully built h2o\n",
            "Installing collected packages: colorama, h2o\n",
            "Successfully installed colorama-0.4.1 h2o-3.26.0.10\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/8f/8b75806399bd4eb3125cb6aa0bad73e279648770e7bb4dee441b24acb959/catboost-0.19.1-cp36-none-manylinux1_x86_64.whl (63.0MB)\n",
            "\u001b[K     |████████████████████████████████| 63.0MB 147kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.17.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.6.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.6.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.19.1\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.14.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX2LrM3heeq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lXXw9JQeBo1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import mlxtend as mlx\n",
        "import hyperopt as hopt\n",
        "import featuretools as ft\n",
        "import h2o\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import scipy as sc\n",
        "import tpot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bGLwDZLyBo1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d92601f0-ccd0-4284-f0ba-93ea2ff6a038"
      },
      "source": [
        "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression,RidgeClassifier,SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier,VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import roc_auc_score,make_scorer\n",
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "from hyperopt.pyll import scope as ho_scope\n",
        "from hyperopt.pyll.stochastic import sample as ho_sample"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aFHl-B_LBo1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from catboost import CatBoostClassifier,Pool,cv\n",
        "from catboost import train as cb_train\n",
        "from sklearn.calibration import CalibratedClassifierCV,calibration_curve\n",
        "from sklearn.feature_selection import mutual_info_classif,SelectKBest,chi2,RFECV\n",
        "import time\n",
        "import warnings\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5Y_KNXLPBo12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SMPFHGuqBo1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s0D6hvQSBo2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train['target'].value_counts()/train.shape[0]\n",
        "### 0    0.69412\n",
        "### 1    0.30588"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vakq6huyBo2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "ded96162-4ffc-4646-964d-65efda864c84"
      },
      "source": [
        "#### Numer of unique values in each variable in train and test\n",
        "for i in train.columns:\n",
        "    if i!='id':\n",
        "        print('Number of Unique values in %s for train : %s and test : %s' % (i,train[i].nunique(),test[i].nunique()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unique values in bin_0 for train : 2 and test : 2\n",
            "Number of Unique values in bin_1 for train : 2 and test : 2\n",
            "Number of Unique values in bin_2 for train : 2 and test : 2\n",
            "Number of Unique values in bin_3 for train : 2 and test : 2\n",
            "Number of Unique values in bin_4 for train : 2 and test : 2\n",
            "Number of Unique values in nom_0 for train : 3 and test : 3\n",
            "Number of Unique values in nom_1 for train : 6 and test : 6\n",
            "Number of Unique values in nom_2 for train : 6 and test : 6\n",
            "Number of Unique values in nom_3 for train : 6 and test : 6\n",
            "Number of Unique values in nom_4 for train : 4 and test : 4\n",
            "Number of Unique values in nom_5 for train : 222 and test : 222\n",
            "Number of Unique values in nom_6 for train : 522 and test : 522\n",
            "Number of Unique values in nom_7 for train : 1220 and test : 1219\n",
            "Number of Unique values in nom_8 for train : 2215 and test : 2214\n",
            "Number of Unique values in nom_9 for train : 11981 and test : 11839\n",
            "Number of Unique values in ord_0 for train : 3 and test : 3\n",
            "Number of Unique values in ord_1 for train : 5 and test : 5\n",
            "Number of Unique values in ord_2 for train : 6 and test : 6\n",
            "Number of Unique values in ord_3 for train : 15 and test : 15\n",
            "Number of Unique values in ord_4 for train : 26 and test : 26\n",
            "Number of Unique values in ord_5 for train : 192 and test : 192\n",
            "Number of Unique values in day for train : 7 and test : 7\n",
            "Number of Unique values in month for train : 12 and test : 12\n",
            "Number of Unique values in target for train : 2 and test : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5GMlrQsLBo2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "0875f590-cb5e-4af8-a1b1-233ad3365209"
      },
      "source": [
        "#### Columns where train and test have different category values\n",
        "for i in train.columns.tolist():\n",
        "    s1 = len(set(train[i].unique()).difference(set(test[i].unique())))\n",
        "    s2 = len(set(test[i].unique()).difference(set(train[i].unique())))\n",
        "    print('For variable %s : Category in train but not in test : %s and in test but not in train : %s' % (i,s1,s2))\n",
        "    \n",
        "### nom_7,nom_8,nom_9 are variables whcich have varying category labels in train and test"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For variable id : Category in train but not in test : 300000 and in test but not in train : 200000\n",
            "For variable bin_0 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable bin_1 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable bin_2 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable bin_3 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable bin_4 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable nom_0 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable nom_1 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable nom_2 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable nom_3 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable nom_4 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable nom_5 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable nom_6 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable nom_7 : Category in train but not in test : 1 and in test but not in train : 0\n",
            "For variable nom_8 : Category in train but not in test : 5 and in test but not in train : 4\n",
            "For variable nom_9 : Category in train but not in test : 229 and in test but not in train : 87\n",
            "For variable ord_0 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable ord_1 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable ord_2 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable ord_3 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable ord_4 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable ord_5 : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable day : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable month : Category in train but not in test : 0 and in test but not in train : 0\n",
            "For variable target : Category in train but not in test : 1 and in test but not in train : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lpqKkJ5WBo2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.DataFrame({ k:train[k].nunique() for k in train.columns if k not in ['id','target']},index = [0]).T.reset_index()\n",
        "high_card_feats = df1[df1[0]>12]['index'].values.tolist()\n",
        "low_card_feats = df1[df1[0]<=12]['index'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NBbUKXqfBo2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cat_Encode:\n",
        "        \n",
        "    ### Encoding categorical variables using category_encoders package. \n",
        "    ### This returns a transformed dataframe.\n",
        "    \n",
        "    def __init__(self,methods,**params):\n",
        "        self.methods = methods\n",
        "        self.params = params\n",
        "        self.method_obj = self.get_method_obj()\n",
        "        \n",
        "    def get_method_obj(self):\n",
        "        if self.methods == 'target_encode':\n",
        "             return ce.target_encoder.TargetEncoder(**self.params)\n",
        "        elif self.methods == 'woe':\n",
        "            return ce.woe.WOEEncoder(**self.params)\n",
        "        elif self.methods == 'ohe':\n",
        "            return ce.one_hot.OneHotEncoder(**self.params)\n",
        "        elif self.methods == 'helmert':\n",
        "            return ce.helmert.HelmertEncoder(**self.params)\n",
        "        elif self.methods == 'james-stein':\n",
        "            return ce.james_stein.JamesSteinEncoder(**self.params)\n",
        "        elif self.methods == 'loo':\n",
        "            return ce.leave_one_out.LeaveOneOutEncoder(**self.params)\n",
        "        elif self.methods == 'm-estimate':\n",
        "            return ce.m_estimate.MEstimateEncoder(**self.params)\n",
        "        elif self.methods == 'hashing':\n",
        "            return ce.hashing.HashingEncoder(**self.params)\n",
        "        elif self.methods == 'cat_boost':\n",
        "            return ce.cat_boost.CatBoostEncoder(**self.params)\n",
        "        elif self.methods == 'binary':\n",
        "            return ce.binary.BinaryEncoder(**self.params)\n",
        "        else:\n",
        "            print(\"Methods can be from : [target_encode,woe,ohe,m-estimate,hashing,cat_boost,binary]\")\n",
        "    \n",
        "    def print_method(self):\n",
        "        print(self.method_obj)\n",
        "        \n",
        "    def return_method_obj(self):\n",
        "        return self.method_obj\n",
        "        \n",
        "    def fit_(self,data,**kwargs):\n",
        "        self.method_fit_ = self.method_obj.fit(data,**kwargs)\n",
        "        return self\n",
        "    \n",
        "    def transform_(self,data):\n",
        "        self.method_transform_ = self.method_obj.transform(data)\n",
        "        return self.method_transform_\n",
        "\n",
        "    def fit_transform_(self,data,**kwargs):\n",
        "        return self.method_obj.fit_transform(data,**kwargs)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2rdjK0boBo29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tar_encode = Cat_Encode(methods = \"target_encode\", cols=x_train.select_dtypes(include = object).columns.tolist(), min_samples_leaf=100, smoothing=1)\n",
        "a1 = tar_encode.fit_transform_(x_train,y = y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTcKwQQjrogF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tv7ddaZVBo3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model_Build:\n",
        "    \n",
        "    def __init__(self,model,cv_type = 'stratified k fold',scoring = None,verbose = 0,cv_params = None,feat_sel = None):\n",
        "        self.model = model\n",
        "        self.cv_type = cv_type\n",
        "        self.scoring = scoring\n",
        "        self.verbose = verbose\n",
        "        self.cv_params  = cv_params\n",
        "        self.feat_sel_func = feat_sel\n",
        "        \n",
        "    def _check_cv_type(self):\n",
        "        assert isinstance(self.cv,int) , 'CV must be of type int'\n",
        "        assert isinstance(self.cv_type,str), 'CV type must be of string and can be : stratified k fold,k fold,repeated k fold,repeated stratified k fold'\n",
        "            \n",
        "    \n",
        "    def get_cv_func(self):\n",
        "        if self.cv_type == 'stratified k fold':\n",
        "            return StratifiedKFold(**self.cv_params)\n",
        "        elif self.cv_type == 'k fold':\n",
        "            return KFold(**self.cv_params)\n",
        "        elif self.cv_type == 'repeated k fold':\n",
        "            return RepeatedKFold(**self.cv_params)\n",
        "        elif self.cv_type == 'repeated stratified k fold':\n",
        "            return RepeatedStratifiedKFold(**self.cv_params)\n",
        "        else:\n",
        "            self._check_cv_type()\n",
        "        \n",
        "    def get_cv_folds(self,X,Y):\n",
        "        \n",
        "        cv_func = self.get_cv_func()\n",
        "        print(cv_func)\n",
        "        train_ind_list = []\n",
        "        test_ind_list = []\n",
        "        for train_ind,test_ind in cv_func.split(X,Y):\n",
        "            train_ind_list.append(train_ind)\n",
        "            test_ind_list.append(test_ind)\n",
        "        \n",
        "        return train_ind_list,test_ind_list\n",
        "    \n",
        "    def cv_feat_process(self,X,cv_feat_func,Y = None,data_class = None):\n",
        "        if data_class == 'train':\n",
        "            return cv_feat_func.fit_transform_(X,y = Y)\n",
        "        elif data_class == 'test':\n",
        "            return cv_feat_func.transform_(X)\n",
        "        \n",
        "    def feat_sel_(self,X,Y= None,data_class = None):\n",
        "        if data_class == 'train':\n",
        "            return self.feat_sel_func.fit_transform_(X,y = Y)\n",
        "        else:\n",
        "            return self.feat_sel_func.transform_(X)\n",
        "    \n",
        "    def cv_fit_(self,X,Y,sample_weight = None,cv_feat_func = None):\n",
        "        train_cv_ind,test_cv_ind = self.get_cv_folds(X,Y)\n",
        "        cv_scores = []\n",
        "        k = 1\n",
        "        for i,j in zip(train_cv_ind,test_cv_ind):\n",
        "            #print('-------- Started for fold : %s -------' % (k))\n",
        "            x_train,x_val,y_train,y_val = X.loc[i,:],X.loc[j,:],Y[i],Y[j]\n",
        "            \n",
        "            #### Calculating sample weights\n",
        "            wts = y_train[y_train == 0].shape[0]/y_train[y_train == 1].shape[0]\n",
        "            samp_wt = y_train.apply( lambda x: wts if x==1 else 1)\n",
        "            \n",
        "            if cv_feat_func!=None: \n",
        "                x_train = self.cv_feat_process(x_train,cv_feat_func,Y = y_train,data_class = 'train')\n",
        "                x_val = self.cv_feat_process(x_val,cv_feat_func,data_class = 'test')\n",
        "            \n",
        "            if self.feat_sel_func != None:\n",
        "                #a1 = x_train[x_train.drop(high_card_feats,axis = 1)<0].sum().reset_index()\n",
        "                #neg_cols = a1[a1[0]!=0]['index'].tolist()\n",
        "                x_train = self.feat_sel_(x_train,Y = y_train,data_class = 'train')\n",
        "                x_val = self.feat_sel_(x_val,data_class = 'test')\n",
        "                \n",
        "                #x_train = pd.concat([pd.DataFrame(x_train_1,index = x_train.index),x_train[neg_cols]],axis = 1)\n",
        "                #x_val = pd.concat([pd.DataFrame(x_val_1,index = x_val.index),x_val[neg_cols]],axis = 1)\n",
        "                \n",
        "            x_train.index = range(x_train.shape[0])\n",
        "            x_val.index = range(x_val.shape[0])\n",
        "            \n",
        "            model_fit = self.model.fit(x_train,y_train,sample_weight = samp_wt) if sample_weight == True else self.model.fit(x_train,y_train)\n",
        "            model_preds = model_fit.predict_proba(x_val)\n",
        "            cv_scores.append(self.scoring(y_val,model_preds[:,1]))\n",
        "            #print('Score : %s' % (cv_scores[k-1]))\n",
        "            k = k+1\n",
        "        \n",
        "        return cv_scores\n",
        "    \n",
        "    def fit_(self,X,Y,sample_weight = None,cv_feat_func = None):\n",
        "        if cv_feat_func!=None : \n",
        "            X = self.cv_feat_process(X,cv_feat_func,Y= Y,data_class = 'train')\n",
        "            \n",
        "        wts = y_train[y_train == 0].shape[0]/y_train[y_train == 1].shape[0]\n",
        "        samp_wt = y_train.apply( lambda x: wts if x==1 else 1)\n",
        "            \n",
        "        self.model_fit = self.model.fit(X,Y,sample_weight = samp_wt) if sample_weight == True else self.model.fit(X,Y)\n",
        "    \n",
        "    def predict_proba(self,X,cv_feat_func = None):\n",
        "        if cv_feat_func!=None : \n",
        "            X = self.cv_feat_process(X,cv_feat_func,data_class = 'train')\n",
        "        return  self.model_fit.predict_proba(X)  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rxjB8ZHJBo3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Feat_Preprocess:\n",
        "    def __init__(self,cyc_encode = True,ohe_encode = True):\n",
        "        self.cyc_encode = cyc_encode\n",
        "        self.ohe_encode = ohe_encode\n",
        "        \n",
        "    def cyc(self,col, max_val = None):\n",
        "        for c in col:\n",
        "            if max_val == None:\n",
        "                max_val = self.X[c].max()\n",
        "            self.X[c + '_sin'] = np.sin(2 * np.pi * self.X[c]/max_val)\n",
        "            self.X[c + '_cos'] = np.cos(2 * np.pi * self.X[c]/max_val)\n",
        "    \n",
        "    \n",
        "    def ohe(self):\n",
        "        self.X = pd.get_dummies(self.X,columns = self.cols_to_dummy,drop_first = True)\n",
        "        \n",
        "    def fit_(self,X,cyc_col = None,ohe_cols = None):\n",
        "        self.X = X\n",
        "        \n",
        "        if self.cyc_encode:\n",
        "            self.cyc(cyc_col)\n",
        "        \n",
        "        if self.ohe_encode:\n",
        "            self.cols_to_dummy = ohe_cols\n",
        "            self.ohe()\n",
        "        \n",
        "        return self.X\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9dY0KM3SBo3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Encoding cyclical features\n",
        "cols_to_dummy =[ x for x in  df1[(df1[0]>=2) & (df1[0]<=12)]['index'].values.tolist() if x not in ['day','month'] ]\n",
        "train['flag'] = ['train']*train.shape[0]\n",
        "test['flag'] = ['test']*test.shape[0]\n",
        "total_data = pd.concat([train,test],axis = 0)\n",
        "total_data_1 = Feat_Preprocess(cyc_encode=True,ohe_encode=False).fit_(total_data,cyc_col = ['day','month'])\n",
        "train_1 = total_data_1[total_data_1['flag'] == 'train']\n",
        "test_1 = total_data_1[total_data_1['flag'] == 'test']\n",
        "cols_to_drop = ['id','day','month','target','flag']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhwofHZigBvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NC35u_bOBo3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(train_1.drop(cols_to_drop,axis = 1),train_1['target'],test_size = 0.3,stratify = train_1['target'])\n",
        "x_train.index = range(x_train.shape[0])\n",
        "x_test.index = range(x_test.shape[0])\n",
        "y_train.index = range(y_train.shape[0])\n",
        "y_test.index = range(y_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LWBgRXfABo3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SATXZDzPBo3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_loss = float('-inf')\n",
        "obj_call_count = 0\n",
        "#train_2 = train_1.drop(cols_to_drop,axis = 1)\n",
        "#test_2 = test_1.drop(cols_to_drop,axis = 1)\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "def get_params(params):\n",
        "  params['border_count'] = int(params['border_count'])\n",
        "  return params\n",
        "\n",
        "global model    \n",
        "\n",
        "def objective(params):\n",
        "    \n",
        "    global best_loss,obj_call_count\n",
        "    \n",
        "    params_new = get_params(params)\n",
        "\n",
        "    obj_call_count += 1\n",
        "    \n",
        "    \n",
        "    sorted_params = sorted(params.items(), key=lambda z: z[0])\n",
        "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
        "    print('Iteration Number : %s' % (obj_call_count))\n",
        "    print('Params: {}'.format(params_str) )\n",
        "    \n",
        "    \n",
        "    m = Model_Build(model = model(**params),cv_params={'n_splits' : 3,'random_state' : 1993},scoring = roc_auc_score,feat_sel = tar_encode)\n",
        "    cv_scores = m.cv_fit_(x_train,y_train,sample_weight = True)\n",
        "    mean_cv_score = -1*np.mean(cv_scores)\n",
        "    \n",
        "    if mean_cv_score<best_loss:\n",
        "        best_loss = mean_cv_score\n",
        "        \n",
        "    return{'loss':mean_cv_score, 'status': STATUS_OK }\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6dRw2wvGBo36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "618befce-2552-480f-abaf-1f929dac2f81"
      },
      "source": [
        "search_spaces = {'iterations': hp.choice('iterations',[10,50,100,500,1000]),\n",
        "                 'depth': hp.choice('depth',[3,5,7,9]),\n",
        "                 'learning_rate': hp.uniform('learning_rate',0.01, 0.3),\n",
        "                 'random_strength': hp.loguniform('random_strength',1e-9, 10),\n",
        "                 'bagging_temperature': hp.uniform('bagging_temperature',0.0, 1.0),\n",
        "                 'border_count': hp.uniform('border_count',1, 255),\n",
        "                 'l2_leaf_reg': hp.uniform('l2_leaf_reg',2, 30),\n",
        "                 'scale_pos_weight':hp.uniform('scale_pos_weight',0.01, 1.0)}\n",
        "    \n",
        "tar_encode = Cat_Encode(methods = \"target_encode\", cols=x_train.drop(high_card_feats,axis = 1).select_dtypes(include = object).columns.tolist(), min_samples_leaf=100, smoothing=1)\n",
        "\n",
        "model = CatBoostClassifier(devices = '0:4',task_type = 'GPU',\n",
        "                         loss_function='Logloss',early_stopping_rounds=50,\n",
        "                         od_type = 'Iter',cat_features=high_card_feats,\n",
        "                         verbose= False,**params)\n",
        "\n",
        "\n",
        "HYPEROPT_ALGO = tpe.suggest\n",
        "best = fmin(fn = objective,space = search_spaces ,algo = HYPEROPT_ALGO,trials= trials,verbose = 2,show_progressbar=False,max_evals=20)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration Number : 1\n",
            "Params: bagging_temperature=0.10504830601403503 border_count=53 depth=7 iterations=50 l2_leaf_reg=10.420788458942829 learning_rate=0.08499005443155659 random_strength=393.9116441192806 scale_pos_weight=0.8141695124578946\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 2\n",
            "Params: bagging_temperature=0.8311356564953367 border_count=169 depth=9 iterations=100 l2_leaf_reg=9.04162394550018 learning_rate=0.29154890149588947 random_strength=3.9042066907799637 scale_pos_weight=0.6245520995759687\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 3\n",
            "Params: bagging_temperature=0.24469248733614402 border_count=7 depth=5 iterations=10 l2_leaf_reg=25.035713456934527 learning_rate=0.12137457772694656 random_strength=768.6128743019193 scale_pos_weight=0.7253885724674448\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 4\n",
            "Params: bagging_temperature=0.357902133117176 border_count=163 depth=9 iterations=1000 l2_leaf_reg=21.037801387144377 learning_rate=0.21044980378430558 random_strength=9588.1298832646 scale_pos_weight=0.8347560437610636\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 5\n",
            "Params: bagging_temperature=0.7549309343303497 border_count=96 depth=3 iterations=1000 l2_leaf_reg=24.07810580939764 learning_rate=0.2667559783130401 random_strength=4066.5093240981437 scale_pos_weight=0.35226611336702773\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 6\n",
            "Params: bagging_temperature=0.575631232518471 border_count=33 depth=9 iterations=10 l2_leaf_reg=3.4082961269842964 learning_rate=0.07766255177282468 random_strength=5.051158882771831 scale_pos_weight=0.4300978051917853\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 7\n",
            "Params: bagging_temperature=0.04567574627781845 border_count=44 depth=5 iterations=500 l2_leaf_reg=5.961523116249853 learning_rate=0.05115843630322764 random_strength=4.16597313875296 scale_pos_weight=0.1912085080557559\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 8\n",
            "Params: bagging_temperature=0.6846446088175308 border_count=198 depth=9 iterations=1000 l2_leaf_reg=7.559485748787939 learning_rate=0.02493884323615026 random_strength=3957.011822515485 scale_pos_weight=0.6676359548495432\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 9\n",
            "Params: bagging_temperature=0.08862631255102571 border_count=37 depth=3 iterations=500 l2_leaf_reg=13.239069821420218 learning_rate=0.24974624664257458 random_strength=462.2245816724741 scale_pos_weight=0.6952546199354043\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 10\n",
            "Params: bagging_temperature=0.2027613018466382 border_count=221 depth=3 iterations=500 l2_leaf_reg=20.78864350160675 learning_rate=0.15627168486849907 random_strength=7657.214172203862 scale_pos_weight=0.11589147715810688\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 11\n",
            "Params: bagging_temperature=0.3021305889050375 border_count=90 depth=7 iterations=500 l2_leaf_reg=3.4824572431935494 learning_rate=0.08131269073662446 random_strength=29.95159031511439 scale_pos_weight=0.6814390255365391\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 12\n",
            "Params: bagging_temperature=0.8346959378247019 border_count=159 depth=7 iterations=1000 l2_leaf_reg=16.449230707196563 learning_rate=0.23564849085148337 random_strength=2.130628464369512 scale_pos_weight=0.022519646620878003\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 13\n",
            "Params: bagging_temperature=0.3521897469402495 border_count=191 depth=7 iterations=500 l2_leaf_reg=9.307310161465315 learning_rate=0.01349419688875814 random_strength=10163.70609522663 scale_pos_weight=0.4407856270846421\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 14\n",
            "Params: bagging_temperature=0.7632380032667377 border_count=235 depth=9 iterations=10 l2_leaf_reg=27.737504990882524 learning_rate=0.10992871209074713 random_strength=2.8656731325641775 scale_pos_weight=0.9015194594992919\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 15\n",
            "Params: bagging_temperature=0.25575431708399865 border_count=222 depth=5 iterations=50 l2_leaf_reg=13.948498474855327 learning_rate=0.2358569493504113 random_strength=8833.075182089104 scale_pos_weight=0.2653426702749374\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 16\n",
            "Params: bagging_temperature=0.4830571555162012 border_count=232 depth=9 iterations=10 l2_leaf_reg=21.963963955014385 learning_rate=0.17600770315880787 random_strength=472.0545838635027 scale_pos_weight=0.2079670389447438\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 17\n",
            "Params: bagging_temperature=0.9831886410088907 border_count=22 depth=9 iterations=500 l2_leaf_reg=11.327775715667201 learning_rate=0.05481690711466776 random_strength=3462.7927406848485 scale_pos_weight=0.5064673180986927\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 18\n",
            "Params: bagging_temperature=0.1795479406091255 border_count=171 depth=9 iterations=100 l2_leaf_reg=29.924862562770155 learning_rate=0.2770841947465987 random_strength=158.6661523884464 scale_pos_weight=0.5030375867888419\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 19\n",
            "Params: bagging_temperature=0.6452112864737429 border_count=220 depth=3 iterations=1000 l2_leaf_reg=26.662992594727058 learning_rate=0.17071703262313315 random_strength=17752.210863355293 scale_pos_weight=0.2901631556683703\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n",
            "Iteration Number : 20\n",
            "Params: bagging_temperature=0.9254673226078717 border_count=84 depth=7 iterations=50 l2_leaf_reg=10.005240652659884 learning_rate=0.26931822116820126 random_strength=436.700978716818 scale_pos_weight=0.4500045119914516\n",
            "StratifiedKFold(n_splits=3, random_state=1993, shuffle=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviLgWTTyOPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "686b0532-dd5f-4cdf-b41b-29e731e9886e"
      },
      "source": [
        "print(best)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bagging_temperature': 0.6452112864737429, 'border_count': 220.31628698835166, 'depth': 0, 'iterations': 4, 'l2_leaf_reg': 26.662992594727058, 'learning_rate': 0.17071703262313315, 'random_strength': 17752.210863355293, 'scale_pos_weight': 0.2901631556683703}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l3wIA9T7Bo4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search_spaces = {'iterations': hp.choice('iterations',[10,50,100,500,1000]),\n",
        "                 'depth': hp.choice('depth',[3,5,7,9]),\n",
        "                 'learning_rate': hp.uniform('learning_rate',0.01, 0.3),\n",
        "                 'random_strength': hp.loguniform('random_strength',1e-9, 10),\n",
        "                 'bagging_temperature': hp.uniform('bagging_temperature',0.0, 1.0),\n",
        "                 'border_count': hp.uniform('border_count',1, 255),\n",
        "                 'l2_leaf_reg': hp.uniform('l2_leaf_reg',2, 30),\n",
        "                 'scale_pos_weight':hp.uniform('scale_pos_weight',0.01, 1.0)}\n",
        "    \n",
        "tar_encode = Cat_Encode(methods = \"target_encode\", cols=x_train.select_dtypes(include = object).columns.tolist(), min_samples_leaf=100, smoothing=1)\n",
        "\n",
        "model = LGBMClassifier(random_state = 1993,boosting_type='gbdt',**params)\n",
        "\n",
        "HYPEROPT_ALGO = tpe.suggest\n",
        "best = fmin(fn = objective,space = search_spaces ,algo = HYPEROPT_ALGO,trials= trials,verbose = 2,show_progressbar=False,max_evals=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0_AwHBjWBo4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DEllUKwdBo4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zHA8Fd4aBo4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h7K6bvVdBo4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "txADD7UxBo4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mj8wm0qdBo43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hHZfs8emBo48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = LGBMClassifier(random_state = 1993,boosting_type='gbdt',num_estimators = 100,learning_rate=0.1,num_leaves=50)\n",
        "# optimal params for target encode : min_samples_leaf=100, smoothing=1\n",
        "#model = CatBoostClassifier(random_state = 1993,verbose = 0)\n",
        "#tar_encode = Cat_Encode(methods = \"target_encode\", cols=high_card_feats + cols_to_dummy, min_samples_leaf=100, smoothing=1)\n",
        "#m = Model_Build(model = model,cv_params={'n_splits' : 3,'random_state' : 1993},scoring = roc_auc_score)\n",
        "#m.cv_fit_(x_train,y_train,cv_feat_func=tar_encode,sample_weight = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NFFvB-57Bo5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "tar_encode = Cat_Encode(methods = \"target_encode\", cols=high_card_feats+cols_to_dummy, min_samples_leaf=100, smoothing=1)\n",
        "x_train_encode = tar_encode.fit_transform_(x_train,y = y_train)\n",
        "x_test_encode = tar_encode.transform_(x_test)\n",
        "\n",
        "wts = y_train[y_train == 0].shape[0]/y_train[y_train == 1].shape[0]\n",
        "sample_weight = y_train.apply( lambda x: wts if x==1 else 1)\n",
        "            \n",
        "model_fit_1 = CatBoostClassifier(random_state = 1993,verbose= 0).fit(x_train_encode,y_train,sample_weight=sample_weight)\n",
        "model_preds_1 = model_fit_1.predict_proba(x_test_encode)\n",
        "print(roc_auc_score(y_test,model_preds_1[:,1]))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z0KXn2OFBo5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zhE5we7ABo5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tar_encode = Cat_Encode(methods = \"target_encode\", cols=high_card_feats, min_samples_leaf=100, smoothing=1)\n",
        "#train_encode = tar_encode.fit_transform_(train_2.drop(cols_to_drop,axis = 1),y = train_1['target'])\n",
        "#test_encode = tar_encode.transform_(test_2.drop(cols_to_drop,axis = 1))\n",
        "\n",
        "model_fit_2 = CatBoostClassifier(devices = '0:4',task_type = 'GPU',\n",
        "                         loss_function='Logloss',early_stopping_rounds=50,\n",
        "                         od_type = 'Iter',cat_features=high_card_feats,\n",
        "                         verbose= False,**best).fit(train_2,train_1['target'])\n",
        "model_preds_2 = model_fit_2.predict_proba(test_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zG31NSaoBo5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = pd.DataFrame({'id' : test_new['id'],'target' : model_preds_2[:,-1]},index = range(test_new.shape[0]))\n",
        "output.to_csv('Output_CB_Hopt.csv',index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}